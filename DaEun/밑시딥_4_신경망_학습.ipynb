{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dQcqyElstxss"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx2PnMhftglK"
      },
      "source": [
        "# 오차제곱합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_IRXMHcFtc_r"
      },
      "outputs": [],
      "source": [
        "def sum_squares_error(y,t):\n",
        "  return 0.5 * np.sum((y-t)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_Ja2gZ9tpQ_",
        "outputId": "cf950c3c-75f2-4de9-daec-d930b4609c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ]
        }
      ],
      "source": [
        "# 오차제곱합\n",
        "## => 오차제곱합 기준으로 오차가 더 작은게 정답에 더 가깝다!\n",
        "## 정답은 2\n",
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "## 2일 확률이 가장 높다고 추정함\n",
        "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
        "print(sum_squares_error(np.array(y), np.array(t)))\n",
        "## 7일 확률이 가장 높다고 추정함\n",
        "y = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
        "print(sum_squares_error(np.array(y), np.array(t)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdaeBl0ucyT"
      },
      "source": [
        "# 교차 엔트로피 오차"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IuaqlQdet65t"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_error(y,t):\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t*np.log(y+delta)) # delta 더하는 이유: log0방지 ( log0은 음의 무한대 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43k67rVKwQFN",
        "outputId": "0d5d8002-28f8-42ce-c874-19c9a11d7a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ]
        }
      ],
      "source": [
        "# 교차 엔트로피 오차\n",
        "## =>교차 엔트로피 오차 기준에서도 오차가 더 작은게 정답에 더 가깝다!\n",
        "## 정답은 2\n",
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "## 2일 확률이 가장 높다고 추정함\n",
        "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "## 7일 확률이 가장 높다고 추정함\n",
        "y = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXJuzBnGxlx3"
      },
      "source": [
        "# 미니배치 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH3_JQPUxwNb"
      },
      "source": [
        "- 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6PbFhRRxqR7",
        "outputId": "ff38d8d3-1bd2-413b-82c6-62e788a29239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zYEe9DCbxmyB"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append('/content/drive/MyDrive/DACON_사기탐지 ')\n",
        "from mnist import load_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAyLv28Lx07U",
        "outputId": "4aa7446c-a51c-444f-dc9b-714ba8079de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "source": [
        "(x_train, t_train) , (x_test, t_test) = load_mnist(one_hot_label = True, normalize = False)\n",
        "print(x_train.shape) # (60000, 784)\n",
        "print(t_train.shape) # (60000,)\n",
        "print(x_test.shape) # (10000, 784)\n",
        "print(t_test.shape) # (10000,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzlkf12gyI_n"
      },
      "source": [
        "- 랜덤 지정\n",
        "  - np.random.choice :  지정한 범위의 수 중에서 무작위로 원하는 개수만 꺼내기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AD1aSHzlx69S"
      },
      "outputs": [],
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size , batch_size)\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvO9vGXeywDb"
      },
      "source": [
        "# (배치용) 교차 엔트로피 오차 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SjshFdHGyyPW"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_error(y,t):\n",
        "  if y.ndim ==1 :\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(t*np.log(y+1e-7)) / batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlI9xBT49-B1"
      },
      "source": [
        "# 미분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R_dHR4VVzALM"
      },
      "outputs": [],
      "source": [
        "def numerical_diff(f,x):\n",
        "  h = 1e-50\n",
        "  return (f(x+h)-f(x))/h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "miE231A2-GKM"
      },
      "outputs": [],
      "source": [
        "# 중앙 차분으로 개선\n",
        "def numerical_diff(f,x):\n",
        "  h = 1e-4\n",
        "  return (f(x+h)-f(x-h))/(2*h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T14xQi9Q-w7p"
      },
      "outputs": [],
      "source": [
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4\n",
        "    grad = np.zeros_like(x)  # x와 형상이 같은 배열을 생성\n",
        "\n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "        # f(x+h) 계산\n",
        "        x[idx] = tmp_val + h\n",
        "        fxh1 = f(x)\n",
        "\n",
        "        # f(x-h) 계산\n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "\n",
        "        grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
        "        x[idx] = tmp_val  # 값 복원\n",
        "\n",
        "    return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcXzkW4WCnTA"
      },
      "source": [
        "# 경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hvWoFbxjCowA"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(f, init_x, lr = 0.01 , step_num = 100):\n",
        "  x = init_x\n",
        "  for i in range(step_num):\n",
        "    grad = numerical_gradient(f,x)\n",
        "    x -= lr* grad\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5FmKcIbC_Gq"
      },
      "source": [
        "## 문제 : 경사하강법으로 f(x0, x1) = x0**2 + x1**2의 최솟값을 구하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "x9ZlVNKyDEIw"
      },
      "outputs": [],
      "source": [
        "def function_2(x):\n",
        "  return x[0]**2+ x[1]**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk7RXyMEDIZt",
        "outputId": "b4cae81f-ea99-4e1d-cc70-33337390eac3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "init_x = np.array([-3.0 , 4.0])\n",
        "gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDsG76DxFHY8"
      },
      "source": [
        "# 신경망의 기울기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0DBBMzAVFTTT"
      },
      "outputs": [],
      "source": [
        "from common.functions import softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GLzTbE-tDRGe"
      },
      "outputs": [],
      "source": [
        "class simpleNet:\n",
        "    def __init__(self):\n",
        "        self.W = np.random.randn(2, 3)  # 정규분포로 초기화\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.dot(x, self.W)\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        z = self.predict(x)\n",
        "        y = softmax(z)\n",
        "        loss = cross_entropy_error(y, t)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmJ7RTO3PUEg",
        "outputId": "90a280c4-855b-405a-ba98-4ca74e2942ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.52058041 -0.73017004  0.62198633]\n",
            " [ 0.40716329 -0.34643643  1.63328252]]\n"
          ]
        }
      ],
      "source": [
        "net = simpleNet()\n",
        "print(net.W) # 가중치 매개변수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTuKezcBPUEh",
        "outputId": "9fff2ce7-3e4f-4f85-8608-f2d609baf0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.05409872 -0.74989481  1.84314607]\n"
          ]
        }
      ],
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHoDj1INPUEh",
        "outputId": "778efd5a-2519-4d02-87be-8efa7e009653"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "np.argmax(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iie02tixPUEh",
        "outputId": "0864c4a4-b058-4a51-f48a-f194180bfc49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21665164809526016"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "t = np.array([0,0,1])\n",
        "net.loss(x,t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbU14HTSPUEh",
        "outputId": "32a9bdf5-02f7-4b8a-c5f3-023d58b6d846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.0807397   0.03613409 -0.1168738 ]\n",
            " [ 0.12110955  0.05420114 -0.17531069]]\n"
          ]
        }
      ],
      "source": [
        "def f(W):\n",
        "    return net.loss(x,t)\n",
        "dW = numerical_gradient(f, net.W)\n",
        "print(dW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQPSDv5ZPUEi"
      },
      "source": [
        "# 2층 신경망 클래스 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xk9G5OwvPUEi"
      },
      "outputs": [],
      "source": [
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "\n",
        "        return y\n",
        "\n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return cross_entropy_error(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "        grads = {}\n",
        "\n",
        "        batch_num = x.shape[0]\n",
        "\n",
        "        # forward\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "\n",
        "        # backward\n",
        "        dy = (y - t) / batch_num\n",
        "        grads['W2'] = np.dot(z1.T, dy)\n",
        "        grads['b2'] = np.sum(dy, axis=0)\n",
        "\n",
        "        da1 = np.dot(dy, W2.T)\n",
        "        dz1 = sigmoid_grad(a1) * da1\n",
        "        grads['W1'] = np.dot(x.T, dz1)\n",
        "        grads['b1'] = np.sum(dz1, axis=0)\n",
        "\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 미니배치 학습 구현"
      ],
      "metadata": {
        "id": "FT_-V8IuQMoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, t_train) , (x_test, t_test) = load_mnist(one_hot_label = True, normalize = False)\n",
        "\n",
        "train_loss_list= []\n",
        "\n",
        "# 하이퍼파라미터\n",
        "iters_num = 1000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "\n",
        "    # 미니배치 획득\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # 기울기 계산\n",
        "    grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    # grad = network.gradient(x_batch, t_batch)  # 다음 장에서 구현할 더 빠른 방법!\n",
        "\n",
        "    # 매개변수 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    # 학습 경과 기록\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "bCJKOGsFQO2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 그리기\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iod0gDp-SG3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시험데이터로 평가하기"
      ],
      "metadata": {
        "id": "YRZSBKABRS1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loss_list= []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 하이퍼파라미터\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "# 1에폭당 반복수\n",
        "iter_per_epoch = max(train_size / batch_size , 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "\n",
        "    # 미니배치 획득\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # 기울기 계산\n",
        "    grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    # grad = network.gradient(x_batch, t_batch)  # 다음 장에서 구현할 더 빠른 방법!\n",
        "\n",
        "    # 매개변수 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    # 학습 경과 기록\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "        # 1에폭 당 정확도 계산\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc | \"\n",
        "              + str(train_acc) + \", \" + str(test_acc))\n",
        "\n"
      ],
      "metadata": {
        "id": "2U2mJ_cORUZJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}